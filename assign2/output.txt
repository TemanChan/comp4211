
Iteration 1: Inputs: 0 0 
Outputs: 0.4986 
Targets: 0 
-0.00179 -0.00887 -0.00179 -0.00887 -0.00179 -0.00887 -0.00179 -0.00887 -0.0329523 -0.0400323 -0.0225523 -0.0403123 loss: 0.248602

Iteration 2: Inputs: 1 0 
Outputs: 0.483041 
Targets: 1 
-0.00232173 -0.00887 -0.00243598 -0.00887 -0.00215391 -0.00887 -0.00244049 -0.00887 -0.000708348 -0.00778835 0.00969165 -0.00806835 loss: 0.267247

Iteration 3: Inputs: 1 0 
Outputs: 0.499142 
Targets: 1 
-0.00233282 -0.00887 -0.00255788 -0.00887 -0.00200222 -0.00887 -0.00256678 -0.00887 0.0305588 0.0234771 0.0409615 0.023197 loss: 0.250859

Iteration 4: Inputs: 0 1 
Outputs: 0.514705 
Targets: 1 
-0.00233282 -0.00840697 -0.00255788 -0.00851427 -0.00200222 -0.00824935 -0.00256678 -0.00851852 0.0607292 0.0536474 0.0711318 0.0533673 loss: 0.235512

Iteration 5: Inputs: 1 1 
Outputs: 0.529664 
Targets: 0 
-0.00333444 -0.00940859 -0.0034427 -0.00939909 -0.00317542 -0.00942255 -0.00344698 -0.00939872 0.0279188 0.0208425 0.0383134 0.0205627 loss: 0.280544

Iteration 6: Inputs: 0 1 
Outputs: 0.513388 
Targets: 1 
-0.00333444 -0.00898436 -0.0034427 -0.00908238 -0.00317542 -0.00884036 -0.00344698 -0.00908626 0.0581673 0.0510911 0.0685617 0.0508113 loss: 0.236791

Iteration 7: Inputs: 1 0 
Outputs: 0.5285 
Targets: 1 
-0.00248017 -0.00898436 -0.00269235 -0.00908238 -0.00216849 -0.00884036 -0.00270074 -0.00908626 0.0874913 0.0804136 0.097888 0.0801336 loss: 0.222312

Iteration 8: Inputs: 0 1 
Outputs: 0.54294 
Targets: 1 
-0.00248017 -0.00774395 -0.00269235 -0.00794232 -0.00216849 -0.00745256 -0.00270074 -0.00795017 0.115719 0.10864 0.126118 0.10836 loss: 0.208903

Iteration 9: Inputs: 1 0 
Outputs: 0.557034 
Targets: 1 
-0.000899145 -0.00774395 -0.00120804 -0.00794232 -0.000445394 -0.00745256 -0.00122026 -0.00795017 0.143011 0.135929 0.153414 0.135649 loss: 0.196219

Iteration 10: Inputs: 0 0 
Outputs: 0.570527 
Targets: 0 
-0.000899145 -0.00774395 -0.00120804 -0.00794232 -0.000445394 -0.00745256 -0.00122026 -0.00795017 0.108062 0.10098 0.118465 0.1007 loss: 0.325501

Iteration 11: Inputs: 0 1 
Outputs: 0.553117 
Targets: 1 
-0.000899145 -0.0062519 -0.00120804 -0.00654806 -0.000445394 -0.00581687 -0.00122026 -0.00655977 0.13557 0.128486 0.145977 0.128205 loss: 0.199704

Iteration 12: Inputs: 1 1 
Outputs: 0.566639 
Targets: 0 
-0.00325708 -0.00860984 -0.00344275 -0.00878277 -0.00298434 -0.00835582 -0.00345009 -0.00878961 0.100909 0.0938346 0.1113 0.0935548 loss: 0.321079

Iteration 13: Inputs: 1 1 
Outputs: 0.54949 
Targets: 0 
-0.00497281 -0.0103256 -0.00503819 -0.0103782 -0.00487676 -0.0102482 -0.00504078 -0.0103803 0.0671039 0.0600358 0.0774865 0.0597562 loss: 0.30194

Iteration 14: Inputs: 0 1 
Outputs: 0.53283 
Targets: 1 
-0.00497281 -0.00935016 -0.00503819 -0.00950554 -0.00487676 -0.00912191 -0.00504078 -0.00951169 0.0960261 0.0889572 0.10641 0.0886776 loss: 0.218248

Iteration 15: Inputs: 0 1 
Outputs: 0.547146 
Targets: 1 
-0.00497281 -0.00800334 -0.00503819 -0.00825787 -0.00487676 -0.00762945 -0.00504078 -0.00826794 0.123947 0.116876 0.134334 0.116596 loss: 0.205077

Iteration 16: Inputs: 1 1 
Outputs: 0.560767 
Targets: 0 
-0.00711267 -0.0101432 -0.00705598 -0.0102757 -0.00719596 -0.00994865 -0.00705373 -0.0102809 0.0896404 0.0825748 0.100019 0.0822954 loss: 0.31446

Iteration 17: Inputs: 0 0 
Outputs: 0.544201 
Targets: 0 
-0.00711267 -0.0101432 -0.00705598 -0.0102757 -0.00719596 -0.00994865 -0.00705373 -0.0102809 0.0558937 0.0488281 0.0662725 0.0485487 loss: 0.296154

Iteration 18: Inputs: 1 0 
Outputs: 0.527318 
Targets: 1 
-0.00628952 -0.0101432 -0.00633688 -0.0102757 -0.00621996 -0.00994865 -0.00633876 -0.0102809 0.0852434 0.0781786 0.095621 0.0778992 loss: 0.223428

Iteration 19: Inputs: 1 1 
Outputs: 0.541675 
Targets: 0 
-0.00772235 -0.011576 -0.00765095 -0.0115897 -0.00782722 -0.0115559 -0.00764813 -0.0115903 0.0519001 0.0448384 0.0622733 0.0445591 loss: 0.293411

Iteration 20: Inputs: 1 0 
Outputs: 0.525326 
Targets: 1 
-0.00695447 -0.011576 -0.00698756 -0.0115897 -0.00690587 -0.0115559 -0.00698887 -0.0115903 0.0813769 0.0743162 0.0917485 0.074037 loss: 0.225315

Iteration 21: Inputs: 0 1 
Outputs: 0.539867 
Targets: 1 
-0.00695447 -0.0104134 -0.00698756 -0.010528 -0.00690587 -0.0102451 -0.00698887 -0.0105325 0.109787 0.102726 0.120159 0.102447 loss: 0.211722

Iteration 22: Inputs: 1 1 
Outputs: 0.553709 
Targets: 0 
-0.0088321 -0.012291 -0.00874442 -0.0122848 -0.00896088 -0.0123001 -0.00874096 -0.0122846 0.0758765 0.0688181 0.0862446 0.068539 loss: 0.306594

Iteration 23: Inputs: 1 0 
Outputs: 0.537201 
Targets: 1 
-0.00774083 -0.012291 -0.00775467 -0.0122848 -0.0077205 -0.0123001 -0.00775522 -0.0122846 0.104514 0.0974572 0.114881 0.0971781 loss: 0.214183

Iteration 24: Inputs: 1 1 
Outputs: 0.551057 
Targets: 0 
-0.00952168 -0.0140718 -0.00941527 -0.0139454 -0.00967798 -0.0142576 -0.00941106 -0.0139404 0.0707737 0.0637167 0.0811398 0.0634377 loss: 0.303664

Iteration 25: Inputs: 0 0 
Outputs: 0.534827 
Targets: 0 
-0.00952168 -0.0140718 -0.00941527 -0.0139454 -0.00967798 -0.0142576 -0.00941106 -0.0139404 0.0375092 0.0304522 0.0478753 0.0301731 loss: 0.28604

Iteration 26: Inputs: 1 0 
Outputs: 0.518156 
Targets: 1 
-0.00895763 -0.0140718 -0.00895735 -0.0139454 -0.00895806 -0.0142576 -0.00895733 -0.0139404 0.0674415 0.0603862 0.0778053 0.0601071 loss: 0.232173

Iteration 27: Inputs: 0 0 
Outputs: 0.533169 
Targets: 0 
-0.00895763 -0.0140718 -0.00895735 -0.0139454 -0.00895806 -0.0142576 -0.00895733 -0.0139404 0.0342651 0.0272098 0.0446289 0.0269307 loss: 0.284269

Iteration 28: Inputs: 0 0 
Outputs: 0.516623 
Targets: 0 
-0.00895763 -0.0140718 -0.00895735 -0.0139454 -0.00895806 -0.0142576 -0.00895733 -0.0139404 0.00201186 -0.00504349 0.0123756 -0.00532251 loss: 0.2669

Iteration 29: Inputs: 0 1 
Outputs: 0.500499 
Targets: 1 
-0.00895763 -0.0140404 -0.00895735 -0.0140241 -0.00895806 -0.0140644 -0.00895733 -0.0140235 0.033011 0.0259576 0.0433719 0.0256787 loss: 0.249501

Iteration 30: Inputs: 1 0 
Outputs: 0.515925 
Targets: 1 
-0.00845878 -0.0140404 -0.00856508 -0.0140241 -0.00830264 -0.0140644 -0.00856929 -0.0140235 0.0630996 0.0560462 0.0734605 0.0557673 loss: 0.234328

Iteration 31: Inputs: 1 1 
Outputs: 0.530659 
Targets: 0 
-0.0095011 -0.0150828 -0.00949089 -0.0149499 -0.00951611 -0.0152779 -0.00949049 -0.0149447 0.0304298 0.0233779 0.0407885 0.023099 loss: 0.281599

Iteration 32: Inputs: 1 0 
Outputs: 0.514638 
Targets: 1 
-0.00903996 -0.0150828 -0.00913662 -0.0149499 -0.00889799 -0.0152779 -0.00914044 -0.0149447 0.060595 0.0535432 0.0709534 0.0532644 loss: 0.235576

Iteration 33: Inputs: 1 0 
Outputs: 0.529625 
Targets: 1 
-0.00815241 -0.0150828 -0.00835235 -0.0149499 -0.00785871 -0.0152779 -0.00836026 -0.0149447 0.0897578 0.0827046 0.100118 0.0824257 loss: 0.221253

Iteration 34: Inputs: 0 0 
Outputs: 0.54426 
Targets: 0 
-0.00815241 -0.0150828 -0.00835235 -0.0149499 -0.00785871 -0.0152779 -0.00836026 -0.0149447 0.0560081 0.0489549 0.0663686 0.048676 loss: 0.296219

Iteration 35: Inputs: 1 0 
Outputs: 0.527361 
Targets: 1 
-0.00732766 -0.0150828 -0.00763147 -0.0149499 -0.0068814 -0.0152779 -0.00764348 -0.0149447 0.0853395 0.0782834 0.0957044 0.0780043 loss: 0.223387

Iteration 36: Inputs: 1 0 
Outputs: 0.541913 
Targets: 1 
-0.00611461 -0.0150828 -0.00651871 -0.0149499 -0.00552102 -0.0152779 -0.00653469 -0.0149447 0.113665 0.106604 0.124036 0.106325 loss: 0.209844

Iteration 37: Inputs: 0 1 
Outputs: 0.555672 
Targets: 1 
-0.00611461 -0.0135242 -0.00651871 -0.0134882 -0.00552102 -0.0135771 -0.00653469 -0.0134867 0.140884 0.133825 0.151252 0.133546 loss: 0.197427

Iteration 38: Inputs: 1 0 
Outputs: 0.569275 
Targets: 1 
-0.00425471 -0.0135242 -0.004752 -0.0134882 -0.00352423 -0.0135771 -0.00477167 -0.0134867 0.167207 0.160143 0.177583 0.159863 loss: 0.185524

Iteration 39: Inputs: 1 0 
Outputs: 0.582169 
Targets: 1 
-0.00213043 -0.0135242 -0.00271746 -0.0134882 -0.00126812 -0.0135771 -0.00274068 -0.0134867 0.192562 0.185492 0.202948 0.185212 loss: 0.174583

Iteration 40: Inputs: 1 1 
Outputs: 0.593896 
Targets: 0 
-0.00557799 -0.0169717 -0.00603843 -0.0168091 -0.00490164 -0.0172106 -0.00605664 -0.0168027 0.157033 0.149972 0.167404 0.149693 loss: 0.352713

Iteration 41: Inputs: 1 0 
Outputs: 0.577172 
Targets: 1 
-0.0035525 -0.0169717 -0.00410401 -0.0168091 -0.00274238 -0.0172106 -0.00412582 -0.0168027 0.182758 0.175692 0.193138 0.175412 loss: 0.178784

Iteration 42: Inputs: 0 1 
Outputs: 0.589142 
Targets: 1 
-0.0035525 -0.0147 -0.00410401 -0.0146252 -0.00274238 -0.0148098 -0.00412582 -0.0146223 0.207409 0.200345 0.217786 0.200066 loss: 0.168805

Iteration 43: Inputs: 1 1 
Outputs: 0.600854 
Targets: 0 
-0.0072882 -0.0184357 -0.00771246 -0.0182337 -0.006665 -0.0187324 -0.00772924 -0.0182257 0.171713 0.164657 0.182077 0.164378 loss: 0.361026

Iteration 44: Inputs: 1 1 
Outputs: 0.583466 
Targets: 0 
-0.0103313 -0.0214788 -0.0106305 -0.0211517 -0.00989184 -0.0219593 -0.0106424 -0.0211388 0.136718 0.129666 0.147077 0.129388 loss: 0.340432

Iteration 45: Inputs: 1 1 
Outputs: 0.566383 
Targets: 0 
-0.0127079 -0.0238554 -0.0128846 -0.0234058 -0.0124485 -0.0245159 -0.0128915 -0.023388 0.102496 0.0954441 0.112856 0.0951652 loss: 0.32079

Iteration 46: Inputs: 0 0 
Outputs: 0.550572 
Targets: 0 
-0.0127079 -0.0238554 -0.0128846 -0.0234058 -0.0124485 -0.0245159 -0.0128915 -0.023388 0.0684376 0.0613854 0.0787969 0.0611065 loss: 0.303129

Iteration 47: Inputs: 0 1 
Outputs: 0.533265 
Targets: 1 
-0.0127079 -0.0228618 -0.0128846 -0.0225145 -0.0124485 -0.0233719 -0.0128915 -0.0225008 0.0971331 0.0900874 0.107483 0.0898087 loss: 0.217842

Iteration 48: Inputs: 1 1 
Outputs: 0.54707 
Targets: 0 
-0.0143533 -0.0245071 -0.0144106 -0.0240405 -0.0142691 -0.0251925 -0.0144128 -0.024022 0.0638469 0.0567983 0.0742008 0.0565195 loss: 0.299285

Iteration 49: Inputs: 0 1 
Outputs: 0.530996 
Targets: 1 
-0.0143533 -0.0235751 -0.0144106 -0.0232114 -0.0142691 -0.0241094 -0.0144128 -0.023197 0.0926892 0.0856474 0.103033 0.0853689 loss: 0.219965

Iteration 50: Inputs: 0 0 
Outputs: 0.545714 
Targets: 0 
-0.0143533 -0.0235751 -0.0144106 -0.0232114 -0.0142691 -0.0241094 -0.0144128 -0.023197 0.0588671 0.0518253 0.069211 0.0515469 loss: 0.297804

Iteration 51: Inputs: 1 0 
Outputs: 0.528692 
Targets: 1 
-0.0134892 -0.0235751 -0.0136498 -0.0232114 -0.0132532 -0.0241094 -0.0136562 -0.023197 0.0880162 0.0809736 0.0983613 0.080695 loss: 0.222131

Iteration 52: Inputs: 0 0 
Outputs: 0.543396 
Targets: 0 
-0.0134892 -0.0235751 -0.0136498 -0.0232114 -0.0132532 -0.0241094 -0.0136562 -0.023197 0.0543098 0.0472671 0.0646549 0.0469886 loss: 0.29528

Iteration 53: Inputs: 0 1 
Outputs: 0.526314 
Targets: 1 
-0.0134892 -0.0227735 -0.0136498 -0.0225137 -0.0132532 -0.0231551 -0.0136562 -0.0225034 0.0834851 0.0764479 0.0938224 0.0761696 loss: 0.224378

Iteration 54: Inputs: 1 0 
Outputs: 0.540871 
Targets: 1 
-0.0122994 -0.0227735 -0.0125603 -0.0225137 -0.0119161 -0.0231551 -0.0125706 -0.0225034 0.111797 0.104757 0.122137 0.104479 loss: 0.2108

Iteration 55: Inputs: 1 0 
Outputs: 0.554834 
Targets: 1 
-0.0107629 -0.0227735 -0.0111206 -0.0225137 -0.0102375 -0.0231551 -0.0111347 -0.0225034 0.139116 0.132073 0.149462 0.131794 loss: 0.198173

Iteration 56: Inputs: 1 1 
Outputs: 0.567483 
Targets: 0 
-0.0131843 -0.0251949 -0.0134194 -0.0248126 -0.012839 -0.0257566 -0.0134287 -0.0247974 0.104878 0.0978367 0.115222 0.0975583 loss: 0.322037

Iteration 57: Inputs: 1 1 
Outputs: 0.550765 
Targets: 0 
-0.0149702 -0.0269808 -0.0150854 -0.0264785 -0.0148009 -0.0277186 -0.0150899 -0.0264586 0.0714639 0.0644199 0.0818109 0.0641414 loss: 0.303342

Iteration 58: Inputs: 1 1 
Outputs: 0.534436 
Targets: 0 
-0.0161575 -0.0281681 -0.0161557 -0.0275488 -0.0161602 -0.0290778 -0.0161556 -0.0275243 0.0389173 0.0318669 0.0492737 0.031588 loss: 0.285622

Iteration 59: Inputs: 0 0 
Outputs: 0.518947 
Targets: 0 
-0.0161575 -0.0281681 -0.0161557 -0.0275488 -0.0161602 -0.0290778 -0.0161556 -0.0275243 0.00652966 -0.000520722 0.0168862 -0.000799551 loss: 0.269306

Iteration 60: Inputs: 1 0 
Outputs: 0.50274 
Targets: 1 
-0.0160561 -0.0281681 -0.0161638 -0.0275488 -0.0158978 -0.0290778 -0.016168 -0.0275243 0.0373564 0.0303061 0.0477129 0.0300273 loss: 0.247268

Iteration 61: Inputs: 0 0 
Outputs: 0.518167 
Targets: 0 
-0.0160561 -0.0281681 -0.0161638 -0.0275488 -0.0158978 -0.0290778 -0.016168 -0.0275243 0.00501373 -0.00203662 0.0153702 -0.00231545 loss: 0.268497

Iteration 62: Inputs: 0 0 
Outputs: 0.502004 
Targets: 0 
-0.0160561 -0.0281681 -0.0161638 -0.0275488 -0.0158978 -0.0290778 -0.016168 -0.0275243 -0.026361 -0.0334114 -0.0160046 -0.0336902 loss: 0.252008

Iteration 63: Inputs: 0 1 
Outputs: 0.486511 
Targets: 1 
-0.0160561 -0.0285907 -0.0161638 -0.0280845 -0.0158978 -0.0293344 -0.016168 -0.0280644 0.00525706 -0.00178336 0.0155989 -0.0020618 loss: 0.263671

Iteration 64: Inputs: 1 0 
Outputs: 0.502109 
Targets: 1 
-0.0159743 -0.0285907 -0.0161915 -0.0280845 -0.0156551 -0.0293344 -0.0162001 -0.0280644 0.0361249 0.0290828 0.0464692 0.0288043 loss: 0.247895

Iteration 65: Inputs: 0 0 
Outputs: 0.517553 
Targets: 0 
-0.0159743 -0.0285907 -0.0161915 -0.0280845 -0.0156551 -0.0293344 -0.0162001 -0.0280644 0.00381767 -0.00322443 0.014162 -0.00350293 loss: 0.267861

Iteration 66: Inputs: 1 1 
Outputs: 0.501375 
Targets: 0 
-0.0160341 -0.0286505 -0.016141 -0.028034 -0.0158769 -0.0295562 -0.0161453 -0.0280096 -0.0268199 -0.0338665 -0.0164689 -0.0341452 loss: 0.251377

Iteration 67: Inputs: 0 1 
Outputs: 0.486288 
Targets: 1 
-0.0160341 -0.0290807 -0.016141 -0.0285771 -0.0158769 -0.0298203 -0.0161453 -0.0285572 0.00480337 -0.00223337 0.0151398 -0.00251166 loss: 0.2639

Iteration 68: Inputs: 0 0 
Outputs: 0.5019 
Targets: 0 
-0.0160341 -0.0290807 -0.016141 -0.0285771 -0.0158769 -0.0298203 -0.0161453 -0.0285572 -0.0265649 -0.0336016 -0.0162285 -0.0338799 loss: 0.251903

Iteration 69: Inputs: 0 0 
Outputs: 0.486219 
Targets: 0 
-0.0160341 -0.0290807 -0.016141 -0.0285771 -0.0158769 -0.0298203 -0.0161453 -0.0285572 -0.0569305 -0.0639673 -0.0465941 -0.0642455 loss: 0.236409

Iteration 70: Inputs: 1 1 
Outputs: 0.471715 
Targets: 0 
-0.0151979 -0.0282445 -0.0152016 -0.0276377 -0.0151926 -0.029136 -0.0152017 -0.0276137 -0.0856555 -0.0926981 -0.0753105 -0.0929766 loss: 0.222515

Iteration 71: Inputs: 1 1 
Outputs: 0.457709 
Targets: 0 
-0.0139821 -0.0270287 -0.0138858 -0.0263219 -0.0141236 -0.028067 -0.0138819 -0.0262939 -0.113441 -0.120492 -0.103083 -0.120771 loss: 0.209498

Iteration 72: Inputs: 1 0 
Outputs: 0.443419 
Targets: 1 
-0.0159298 -0.0270287 -0.0159546 -0.0263219 -0.0158935 -0.028067 -0.0159555 -0.0262939 -0.0793401 -0.0863896 -0.068985 -0.0866684 loss: 0.309782

Iteration 73: Inputs: 1 0 
Outputs: 0.460231 
Targets: 1 
-0.0172596 -0.0270287 -0.0174024 -0.0263219 -0.0170497 -0.028067 -0.0174081 -0.0262939 -0.046085 -0.0531349 -0.0357292 -0.0534137 loss: 0.29135

Iteration 74: Inputs: 0 1 
Outputs: 0.476787 
Targets: 1 
-0.0172596 -0.0277805 -0.0174024 -0.0271886 -0.0170497 -0.0286499 -0.0174081 -0.0271652 -0.0138956 -0.020934 -0.00355681 -0.0212123 loss: 0.273752

Iteration 75: Inputs: 0 0 
Outputs: 0.492551 
Targets: 0 
-0.0172596 -0.0277805 -0.0174024 -0.0271886 -0.0170497 -0.0286499 -0.0174081 -0.0271652 -0.0446732 -0.0517116 -0.0343344 -0.0519899 loss: 0.242606

Iteration 76: Inputs: 0 1 
Outputs: 0.477492 
Targets: 1 
-0.0172596 -0.0285083 -0.0174024 -0.0280311 -0.0170497 -0.0292092 -0.0174081 -0.0280122 -0.0125353 -0.019564 -0.00221063 -0.019842 loss: 0.273015

Iteration 77: Inputs: 0 0 
Outputs: 0.493231 
Targets: 0 
-0.0172596 -0.0285083 -0.0174024 -0.0280311 -0.0170497 -0.0292092 -0.0174081 -0.0280122 -0.0433566 -0.0503853 -0.0330319 -0.0506633 loss: 0.243277

Iteration 78: Inputs: 0 1 
Outputs: 0.478149 
Targets: 1 
-0.0172596 -0.0292138 -0.0174024 -0.0288511 -0.0170497 -0.0297468 -0.0174081 -0.0288367 -0.0112672 -0.0182881 -0.000953933 -0.0185658 loss: 0.272329

Iteration 79: Inputs: 0 1 
Outputs: 0.493955 
Targets: 1 
-0.0172596 -0.029392 -0.0174024 -0.0291402 -0.0170497 -0.0297618 -0.0174081 -0.0291302 0.0198941 0.0128789 0.030199 0.0126015 loss: 0.256082

Iteration 80: Inputs: 1 1 
Outputs: 0.509225 
Targets: 0 
-0.0175759 -0.0297083 -0.0176072 -0.0293449 -0.0175299 -0.030242 -0.0176085 -0.0293306 -0.0111796 -0.0181966 -0.000872239 -0.0184741 loss: 0.25931

Iteration 81: Inputs: 0 0 
Outputs: 0.49391 
Targets: 0 
-0.0175759 -0.0297083 -0.0176072 -0.0293449 -0.0175299 -0.030242 -0.0176085 -0.0293306 -0.0420444 -0.0490614 -0.031737 -0.0493389 loss: 0.243947

Iteration 82: Inputs: 0 0 
Outputs: 0.478491 
Targets: 0 
-0.0175759 -0.0297083 -0.0176072 -0.0293449 -0.0175299 -0.030242 -0.0176085 -0.0293306 -0.0718947 -0.0789117 -0.0615874 -0.0791892 loss: 0.228953

Iteration 83: Inputs: 0 1 
Outputs: 0.464153 
Targets: 1 
-0.0175759 -0.0309057 -0.0176072 -0.0306592 -0.0175299 -0.0312677 -0.0176085 -0.0306495 -0.0390713 -0.0460822 -0.0287728 -0.0463595 loss: 0.287131

Iteration 84: Inputs: 0 0 
Outputs: 0.479975 
Targets: 0 
-0.0175759 -0.0309057 -0.0176072 -0.0306592 -0.0175299 -0.0312677 -0.0176085 -0.0306495 -0.0690217 -0.0760325 -0.0587232 -0.0763098 loss: 0.230376

Iteration 85: Inputs: 1 0 
Outputs: 0.465353 
Targets: 1 
-0.0187235 -0.0309057 -0.0188713 -0.0306592 -0.0185062 -0.0312677 -0.0188772 -0.0306495 -0.0360589 -0.0430703 -0.0257596 -0.0433476 loss: 0.285848

Iteration 86: Inputs: 0 1 
Outputs: 0.481764 
Targets: 1 
-0.0187235 -0.0314888 -0.0188713 -0.0313557 -0.0185062 -0.0316843 -0.0188772 -0.0313504 -0.00421202 -0.0112195 0.00608137 -0.0114966 loss: 0.268568

Iteration 87: Inputs: 0 0 
Outputs: 0.497394 
Targets: 0 
-0.0187235 -0.0314888 -0.0188713 -0.0313557 -0.0185062 -0.0316843 -0.0188772 -0.0313504 -0.0352983 -0.0423057 -0.0250049 -0.0425829 loss: 0.247401

Iteration 88: Inputs: 0 0 
Outputs: 0.481859 
Targets: 0 
-0.0187235 -0.0314888 -0.0188713 -0.0313557 -0.0185062 -0.0316843 -0.0188772 -0.0313504 -0.0653749 -0.0723823 -0.0550815 -0.0726594 loss: 0.232188

Iteration 89: Inputs: 0 0 
Outputs: 0.466861 
Targets: 0 
-0.0187235 -0.0314888 -0.0188713 -0.0313557 -0.0185062 -0.0316843 -0.0188772 -0.0313504 -0.0944255 -0.101433 -0.0841321 -0.10171 loss: 0.21796

Iteration 90: Inputs: 1 0 
Outputs: 0.452875 
Targets: 1 
-0.0203234 -0.0314888 -0.0205901 -0.0313557 -0.0199318 -0.0316843 -0.0206006 -0.0313504 -0.0608512 -0.0678612 -0.0505542 -0.0681384 loss: 0.299346

Iteration 91: Inputs: 0 0 
Outputs: 0.469114 
Targets: 0 
-0.0203234 -0.0314888 -0.0205901 -0.0313557 -0.0199318 -0.0316843 -0.0206006 -0.0313504 -0.090059 -0.0970689 -0.0797619 -0.0973461 loss: 0.220068

Iteration 92: Inputs: 1 1 
Outputs: 0.455766 
Targets: 0 
-0.0190516 -0.030217 -0.0192193 -0.0299849 -0.0188054 -0.0305579 -0.0192259 -0.0299757 -0.117589 -0.124597 -0.107295 -0.124875 loss: 0.207723

Iteration 93: Inputs: 1 0 
Outputs: 0.44154 
Targets: 1 
-0.0210756 -0.030217 -0.0213638 -0.0299849 -0.0206521 -0.0305579 -0.0213752 -0.0299757 -0.0834907 -0.0905017 -0.0731922 -0.090779 loss: 0.311878

Iteration 94: Inputs: 1 1 
Outputs: 0.458931 
Targets: 0 
-0.019887 -0.0290284 -0.0200755 -0.0286966 -0.0196102 -0.029516 -0.0200829 -0.0286834 -0.11125 -0.11826 -0.100953 -0.118537 loss: 0.210617

Iteration 95: Inputs: 0 1 
Outputs: 0.444912 
Targets: 1 
-0.019887 -0.0309344 -0.0200755 -0.0307226 -0.0196102 -0.0312455 -0.0200829 -0.0307143 -0.0774754 -0.0844799 -0.0671864 -0.0847569 loss: 0.308122

Iteration 96: Inputs: 0 1 
Outputs: 0.461445 
Targets: 1 
-0.019887 -0.0322302 -0.0200755 -0.0321356 -0.0196102 -0.0323692 -0.0200829 -0.0321319 -0.0445334 -0.0515343 -0.0342496 -0.0518112 loss: 0.290041

Iteration 97: Inputs: 1 1 
Outputs: 0.477842 
Targets: 0 
-0.0192238 -0.031567 -0.019308 -0.0313681 -0.0191001 -0.0318591 -0.0193113 -0.0313603 -0.0735633 -0.0805628 -0.0632816 -0.0808396 loss: 0.228333

Iteration 98: Inputs: 1 0 
Outputs: 0.463145 
Targets: 1 
-0.0204511 -0.031567 -0.0206521 -0.0313681 -0.0201559 -0.0318591 -0.02066 -0.0313603 -0.0405129 -0.0475138 -0.0302291 -0.0477907 loss: 0.288214

Iteration 99: Inputs: 1 1 
Outputs: 0.479795 
Targets: 0 
-0.0198451 -0.030961 -0.0199413 -0.0306574 -0.0197037 -0.0314069 -0.0199451 -0.0306454 -0.0696726 -0.0766735 -0.0593889 -0.0769504 loss: 0.230203

Iteration 100: Inputs: 0 1 
Outputs: 0.465266 
Targets: 1 
-0.0198451 -0.0321193 -0.0199413 -0.0319321 -0.0197037 -0.0323943 -0.0199451 -0.0319247 -0.0369279 -0.0439237 -0.0266515 -0.0442004 loss: 0.28594

Iteration 101: Inputs: 1 1 
Outputs: 0.481538 
Targets: 0 
-0.0192905 -0.0315648 -0.0192817 -0.0312725 -0.0193035 -0.0319941 -0.0192814 -0.031261 -0.0662022 -0.0731994 -0.0559239 -0.0734762 loss: 0.231879

Training Complete
